{
 "metadata": {
  "name": "",
  "signature": "sha256:0802dc838fa55a2053ce35d7cc5729bcd3ad52e9834e5ac57f58e94c9cb27476"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "**AM 207**: Homework 3"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_ _ _ _ _\n",
      "\n",
      "Pavlos Protopapas <br>\n",
      "Handed out: Thursday, February 20th, 2014<br>\n",
      "Due: 11.59 P.M. Wednesday February 26th, 2014\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "+ Upload your answers in an ipython notebook to the dropbox.\n",
      "\n",
      "+ Your individual submissions use the following filenames: AM207_YOURNAME_HM3.ipynb\n",
      "\n",
      "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format) unless you get permission from the TFs. If you use any special libraries you must include them with your code (program should run as is). \n",
      "\n",
      "+ If you have multiple files (e.g. you've added code files and images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HM2.tar or AM207_YOURNAME_HM2.zip\n",
      "\n",
      "_ _ _ _ _"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 1:  Choosing the simplest integral"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The integral\n",
      "$I = \\int_{0}^{\\infty} f(x) dx $ can be evaluated with MC as \n",
      "$I \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} f(x_i)$\n",
      "where $x$'s are drawn from the uniform distribution. \n",
      "However if the function can be split into $f(x) = h(x) \\, p(x) $, then \n",
      "the integral can be approximated with MC as:\n",
      "\n",
      "$I = \\int_{0}^{\\infty} h(x)\\,p(x) dx  \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} h(x_i)$ where the values of $x$'s are now drawn from $p(x)$. \n",
      "\n",
      "Alternatively we can approximate the integral as \n",
      "$\\hat{I} \\approx \\frac{1}{N} \\sum\\limits_{i=1}^{N} p(x_i) $\n",
      "where the values of $x$'s are now drawn from $h(x)$.\n",
      "\n",
      "The goal of this question is to evaluate the integral:\n",
      "\n",
      "$I=\\int_{0}^{\\infty} \\frac{x\\, \\ln{(x+1)}}{3+(x-3)^2} \\, e^{\\sqrt{x} -x } \\, dx $\n",
      "\n",
      "(a) Which part of the integrand is more suitable as the function to\n",
      "  evaluate, and which is best used as a distribution\n",
      "  to draw random variates from? For the remainder of this question, we shall call the distribution we are sampling from, $g(x)$.\n",
      "\n",
      "[Hint: the distribution $g(x)$ should be easy to find a normalization factor for, \n",
      "and the overall variance of the resulting integrand should be lowered]\n",
      "\n",
      "(b) Implement a Metropolis-Hastings algorithm that has as a\n",
      "  stationary distribution to sample from, $g(x)$.  Run the simulation\n",
      "  50 times for sample size of 150,000 and report the value of the\n",
      "  integral $\\hat{I}$ and the VAR(${\\hat{I}}$).\n",
      "\n",
      "(c) Now use the accept-rejection method to draw from $g(x)$ and compare\n",
      "  the two methods (compare $\\hat{I}$ and VAR(${\\hat{I}}$)).  Which\n",
      "  has the lowest variance? Why do you think this is the case?\n",
      "\n",
      "(d) Also use importance sampling to evaluate the integral.  Which\n",
      "  part of the function is best to use as importance sampling\n",
      "  distribution?  Run the simulation 50 times for sample size of\n",
      "  150,000 and\n",
      "  report the value of the integral  $\\hat{I}$ and the VAR(${\\hat{I}}$).\n",
      "  Note: You can choose a different $g(x)$ for this part. The idea is\n",
      "  that you draw from $g(x)$ using inverse transform."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 2:  Message in a bottle"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes the target distribution is\n",
      "  not available in a functional form but rather as a table or a\n",
      "  matrix. Download <a href=\"./files/pdf_data.txt\">pdf_data.txt</a> from the course\n",
      "  website. This is a MxN matrix representing the pdf values in a 2D\n",
      "  discrete space.  Implement a random walk Metropolis-Hastings to draw\n",
      "  pairs from this distribution.  Experiment with various walk steps.\n",
      "  What is the hidden message?\n",
      "  \n",
      "  Bonus points will be awarded to the most well-presented version of the hidden message, and this will be displayed on the course website.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 3:  Monkey see, monkey do MH"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A good performance test of the ability of a technique to sample the full\n",
      "parameter space is to test the sampling of the Rosenbrock 'Banana' Function.\n",
      "Consider the following specific form of a Banana PDF,\n",
      "\n",
      "$ P(X) \\propto {\\rm exp} \\left[ - \\frac{1}{2a^2} \\left(\\sqrt{x_1^2 + x_2^2} -1 \\right)^2 -  \\frac{1}{2b^2} \\left(x_2 - 1 \\right)^2  \\right] $ where $a=0.1$ and $b=1$.\n",
      "\n",
      "\n",
      "(a) Using the proposal function,\n",
      "\n",
      "$q(x,y) = \\frac{1}{\\sqrt{2 \\pi \\gamma^2}} {\\rm exp}\\left[-\\frac{1}{2 \\gamma^2} |x-y|^2 \\right] $ \n",
      "\n",
      "with $\\gamma = 1$ and beginning at the origin, $x_0 = (0,0)$,\n",
      "construct a M-H algorithm to produce $N=100,000$ samples from\n",
      "$P(X)$. Plot the results. What is a good burn-in factor? Why? [HINT: an acceptance ratio in logarithmic form may work better]\n",
      "\n",
      "(b) Using $P(X)$, construct 3 new samples of $N=100,000$ using\n",
      "$\\gamma = 0.02, 0.8, 5$. Plot the accepted sample histories for each\n",
      "sample. What is the acceptance rate for each sample? What is the most\n",
      "efficient value for $\\gamma$ to select the 100,000 samples?\n",
      "\n",
      "(c) Calculate the mean of each sample from (b), and plot the lagged\n",
      "auto-correlations of the centered components,\n",
      "\n",
      "$\\hat{h}_{i,k} = \\frac{1}{|z|^2} \\sum\\limits_{j=1}^{N-k} z_{j+k} \\times z_j $ where $z_{j} = (x_j - \\bar{x})_i$, $i=1,2$. Interpret your results.\n",
      "\n",
      "(d) Suggest a different (improved) functional form for the proposal\n",
      "and implement this in a M-H algorithm. Compare the acceptance and\n",
      "auto-correlations with that of the $\\gamma = 1$ $q(x,y)$ function from\n",
      "(a)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 4: World Cup Winners"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " Suppose we ask individuals to remember the chronological order of\n",
      "  world cup winners. Individuals make a number of mistakes in the\n",
      "  ordering of winners that can be captured by simple probabilistic\n",
      "  models, such as Mallows model. Here's a simple\n",
      "  example to explain Mallows model:\n",
      "  \n",
      "  Suppose that we are looking at the last four winners: France,\n",
      "  Brazil, Italy, Spain.  We will represent this true ordering by a\n",
      "  vector $\\omega =$ (1,2,3,4) = (France, Brazil, Italy, Spain).\n",
      "  Mallows model now proposes that the remembered orderings tend to be\n",
      "  similar to the true ordering, with very similar orderings being more\n",
      "  likely than dissimilar orderings. Specifically, according to Mallows\n",
      "  model, the probability that an individual remembers an ordering\n",
      "  $\\theta$ is proportional to:\n",
      "\n",
      "$ p(\\theta | \\omega, \\lambda) \\propto  e^{-\\lambda d(\\theta, \\omega)} $\n",
      "\n",
      "In this equation, $d(\\theta, \\omega)$ is the Kendall tau, $\\tau$ is the\n",
      "distance between two orderings. This distance measures the number of\n",
      "adjacent pairwise swaps that are needed to bring the two orderings\n",
      "into alignment.\n",
      "\n",
      "For example, if $\\theta = $ (Brazil, France, Italy,\n",
      "Spain) then $d(\\theta, \\omega) = 1$ because one swap is needed to make\n",
      "the two orderings identical. Similarly, if $\\theta=$ (Brazil, Italy,\n",
      "France, Spain), then $d(\\theta, \\omega) = 2$ because two swaps are\n",
      "needed. Note that in Kendall tau distance, only adjacent items can be\n",
      "swapped.  The scaling parameter $\\lambda$ controls how sharply peaked\n",
      "the distribution of remembered orderings is around the true\n",
      "ordering. Therefore, by increasing $\\lambda$, the model makes it more\n",
      "likely that the correct ordering (or something similar) will be\n",
      "produced.  The problem is now to generate orderings $\\theta$ according\n",
      "to Mallows model, given the true ordering $\\omega$ and scaling\n",
      "parameter $\\lambda$. This can be achieved in very simple ways using a\n",
      "Metropolis sampler.\n",
      "\n",
      "Implement a Metropolis-Hastings algorithm to produce sample\n",
      "guesses from 100 individuals. Choose various proposal distributions\n",
      "and experiment with different values of $\\lambda$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}