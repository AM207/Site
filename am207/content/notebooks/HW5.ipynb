{
 "metadata": {
  "name": "",
  "signature": "sha256:0eed014e08fc8cab4048e3ac33a920883404e8218a2c7d248e215c121a87fe30"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "**AM 207**: Homework 5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_ _ _ _ _\n",
      "\n",
      "Pavlos Protopapas <br>\n",
      "Handed out: Friday, March 7, 2014<br>\n",
      "Due: Friday March 14, 2014\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "+ Upload your answers in an ipython notebook to the dropbox.\n",
      "\n",
      "+ Your individual submissions use the following filenames: AM207_YOURNAME_HM5.ipynb\n",
      "\n",
      "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format) unless you get permission from the TFs. If you use any special libraries you must include them with your code (program should run as is). \n",
      "\n",
      "+ If you have multiple files (e.g. you've added code files and images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HM5.tar or AM207_YOURNAME_HM5.zip\n",
      "\n",
      "_ _ _ _ _"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Question 1\n",
      "\n",
      "Consider\n",
      "\n",
      "$$f(x,y)= \\exp(-100 (\\sqrt{y^2 + x^2} - 1)^2 + (x - 1)^3 - y - 5)$$\n",
      "\n",
      "Sample $ f(x,y) $ by writing a\n",
      "1. Metropolis or Metropolis-Hastings sampler\n",
      "2. Slice sampler\n",
      "3. HMC sampler\n",
      "\n",
      "For each of the samplers, make sure to present a 2d plot of the samples and a traceplot of the samples for each marginal distribution. Describe convergence diagnostics for each sampling method using the Gewecke test and by checking the autocorrelation.  Add any additional diagnostic checks (e.g. histograms, Gelman-Rubin, ESS, etc...) that you feel comfortable with as well. Describe how your samplers fared but use the same burnin and thinning parameters to make the comparison fair."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Question 2\n",
      "\n",
      "### Bayes Evidence\n",
      "Introduced by Harold Jeffreys, a 'Bayes factor' is a Bayesian alternative to frequentist hypothesis testing that is most often used for the comparison of multiple models usually to determine which model better fits the data (Jeffreys, 1961). Bayes factors are notoriously difficult to compute.\n",
      "\n",
      "This is often called the marginal likelihood, integrated likelihood or\n",
      "evidence for a model $M$ and is difficult to compute in general.\n",
      "\n",
      "$$ {\\cal E_M}= P(D \\vert M) = \\int p(D|\\theta_M) p(\\theta_M \\vert M) \\, d \\theta_M $$\n",
      "\n",
      "where M is the model (we shall assume here that two models $M_1$ and $M_2$ have the same parameters but a different functional form for the likelihood).\n",
      "\n",
      "This can be only calculated up to a normalization factor. \n",
      "\n",
      "### Cosmology\n",
      "In the 1920s, Edwin Hubble, using the newly constructed 100\" telescope at Mount Wilson Observatory, detected variable stars in several nebulae. Nebulae are diffuse objects whose nature was a topic of heated debate in the astronomical community: were they interstellar clouds in our own Milky Way galaxy, or whole galaxies outside our galaxy? This was a difficult question to answer because it is notoriously difficult to measure the distance to most astronomical bodies since there is no point of reference for comparison. Hubble's discovery was revolutionary because these variable stars had a characteristic pattern resembling a class of stars called Cepheid variables. Earlier, Henrietta Levitt, part of a group of female astronomers working at **Harvard College Observatory**, had shown there was a tight correlation between the period of a Cepheid variable star and its luminosity (intrinsic brightness). By knowing the luminosity of a source it is possible to measure the distance to that source by measuring how bright it appears to us: the dimmer it appears the farther away it is. Thus, by measuring the period of these stars (and hence their luminosity) and their apparent brightness, Hubble was able to show that these nebula were not clouds within our own Galaxy, but were external galaxies far beyond the edge of our own Galaxy.\n",
      "\n",
      "Hubble's second revolutionary discovery was based on comparing his measurements of the Cepheid-based galaxy distance determinations with measurements of the relative velocities of these galaxies. He showed that more distant galaxies were moving away from us more rapidly:\n",
      "\n",
      "$$v = H_0 d$$\n",
      "\n",
      "where v is the speed at which a galaxy moves away from us, and d is its distance. The constant of proportionality Ho is now called the Hubble constant. The common unit of velocity used to measure the speed of a galaxy is km/sec, while the most common unitfor measuring the distance to nearby galaxies is called the Megaparsec (Mpc) which is equal to 3.26 million light years or 30,800,000,000,000,000,000 km! Thus the units of the Hubble constant are (km/sec)/Mpc.\n",
      "\n",
      "The Hubble parameter measures the expansion rate at which the universe expands. Think about the Pythagoras theorem: it tells us that $ds^2 = dx^2 + dy^2$. This is true for a static space. But if space is expanding the the pythagoras theorem reads like $ds^2 = a(t) * (dx^2 + dy^2)$. $a(t)$ measures how fast the [angles of the] triangle is expanding with time t. This is what happens to the universe. The Hubble parameter simply measures the rate at which a(t) changes and is defined as:  $H(t)  = \\frac{da(t)}{dt}\\frac{1}{a(t)}$. Thus $H(t)$ tells us how fast space is growing. Astronomers measure it at different times to understand the nature of the universe.\n",
      "\n",
      "The Hubble parameter can be obtained from the Friedmann-Robertson Walker equations as a function of the redshift $z$.  Cosmological redshift is seen due to the expansion of the universe, and sufficiently distant light sources (generally those more than a few million light years away) show redshift corresponding to the rate of increase in their distance from Earth. \n",
      "This equation has the following parameters\n",
      "\n",
      "* the equation of state $w$ which is known to most likely have a value between -0.2 and -1.8\n",
      "* the Hubble constant $H_0$ which is known to be most likely between 50 and 90 with a mean around 70\n",
      "* the fraction of matter in the universe $\\Omega_M$ (which being a fraction is confined to be between 0 and 1, with mean known to be roughly around 0.3)\n",
      "\n",
      "$$H(z; w, H_0, \\Omega_m)=H_0 (z+1)^{3/2} \\sqrt{ \\Omega_m + (1 - \\Omega_m) (z+1)^{3w}} $$ \n",
      "\n",
      "\n",
      "Here we can assume that the observed values of $H$ differ from the functional values $H(z; w, H_0,\\Omega_m)$ by additive noise, and we will further assume that this noise follows independent, identically distributed,  Gaussian\n",
      "distributions with zero mean and variance $\\sigma_i^2$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider two models, with fixed $w$, and the other parameters undetermined:\n",
      "\n",
      "**MODEL 1** An accelerated expansion of the universe can be characterized by the equation of state of dark energy. In the simplest case, the equation of state of the cosmological constant is:\n",
      "\n",
      " $w=-1$\n",
      "\n",
      "**MODEL 2:** Phantom energy is a hypothetical form of dark energy that is even more potent than the cosmological constant at increasing the expansion of the universe (i.e., it satisfies the equation of state with  w < -1). If it exists, it could cause the expansion of the universe to accelerate so quickly that a scenario known as the Big Rip would occur.\n",
      "\n",
      "$w=-1.3$\n",
      "\n",
      "Consider gaussian priors for the other parameters $\\Omega_m$ and $H_0$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Data ### \n",
      "Recent measurements of $H(z)$ between redshift $0.1 < z < 2$  from the cosmic chronometers project [Moresco et al arXiv:1010.0831] are given below.   The cosmic chronometer method is the only method that provides cosmology-independent, direct  measurements of the expansion history of the universe (i.e. H vs z measurements).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = \"\"\"z      Hz      errHz\n",
      "0.090   69      12\n",
      "0.170   83      8\n",
      "0.179   75      4\n",
      "0.199   75      5\n",
      "0.270   77      14\n",
      "0.352   83      14\n",
      "0.400   95      17\n",
      "0.480   97      62\n",
      "0.593   104     13\n",
      "0.680   92      8\n",
      "0.781   105     12\n",
      "0.875   125     17\n",
      "0.880   90      40\n",
      "0.900   117     23\n",
      "1.037   154     20\n",
      "1.300   168     17\n",
      "1.430   177     18\n",
      "1.530   140     14\n",
      "1.750   202     40\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Using Bayesian methodology, calculate the joint posteriors of all parameters and provide the MAP values for all of them, for each of Model 1 and Model 2. Use a slice sampler to make your samples for each parameter. Plot the marginal and joint posterior distributions of the parameters, and estimate the MAP values of the parameters by creating a two dimensional histogram.\n",
      "\n",
      "2. Calculate the Bayesian evidence ration for Model 1 and Model 2. Which model is more likely?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}