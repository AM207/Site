{
 "metadata": {
  "name": "",
  "signature": "sha256:6f4df84c1227ce4a0437fabac3089d409bafb5b87b02322d369e8e57d4164f3e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "**AM 207**: Homework 9"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_ _ _ _ _\n",
      "\n",
      "Pavlos Protopapas <br>\n",
      "Handed out: Tuesday April 15th, 2014<br>\n",
      "Due: Thursday April 24th, 2014, 11.59PM\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "+ Upload your answers in an ipython notebook to the dropbox.\n",
      "\n",
      "+ Your individual submissions use the following filenames: AM207_YOURNAME_HM9.ipynb\n",
      "\n",
      "+ Your code should be in code cells as part of your ipython notebook. Do not use a different language (or format) unless you get permission from the TFs. If you use any special libraries you must include them with your code (program should run as is). \n",
      "\n",
      "+ If you have multiple files (e.g. you've added code files and images) create a tarball for all files in a single file and name it: AM207_YOURNAME_HM9.tar or AM207_YOURNAME_HM9.zip\n",
      "\n",
      "_ _ _ _ _"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Question 1. Hidden NASDAQ moves"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the following simple HMM for the NASDAQ prices. \n",
      "\n",
      "$$ x_t =  \\alpha x_{t-1} + \\tau $$\n",
      "\n",
      "where $x_t$ is the 'hidden'  price at time $t$ and $\\alpha$  is a parameter to be set,  $\\tau \\sim N(0, \\sigma_\\tau^2)$. \n",
      "\n",
      "$$ y_t = \\beta x_t + \\omega $$\n",
      "\n",
      "where $x_t$ is the actual price,  $\\beta$ is another parameter and  $\\omega \\sim N(0, \\sigma_\\omega^2)$. \n",
      "\n",
      "Use file [NASDAQ.txt](./files/NASDAQ.txt).\n",
      "\n",
      " \n",
      "1. Choose $\\alpha =0.995$, $\\sigma_\\tau=1$, $\\beta=2$ and $\\sigma_\\omega=1$ and implement a SMC to track the prices.\n",
      "2. Assume you start with \\$1000. At each step predict if the price will go up or down. If your prediction is that the price will go up, **buy** stocks. At each time, also consider selling stocks. Use the first 1000 points for the sequential mc to track and invest for the rest of the points. \n",
      "3. Now experiment with various values of the parameters. Used a fixed seed=12 and try to maximize your profits. Explain your strategy.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Question 2. Separate the bayesian irises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this problem is to introduce you to the idea of classification \n",
      "using Bayesian inferences. \n",
      "\n",
      "You are given the famous *Fisher flower Iris data set*\n",
      "which is a  multivariate data set introduced by Sir Ronald Fisher (1936) as an example of discriminant analysis.\n",
      "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, you will build a model to predict\n",
      "the species. \n",
      "\n",
      "For this problem only consider two classes: versicolor and virginica. \n",
      "\n",
      "The iris data can be obtained [here](./files/iris.txt).\n",
      "\n",
      "Lets $(X, Y )$ be our dataset, where $X=\\{\\vec{x}_1, \\ldots \\vec{x}_n\\}$ and $\\vec{x}_i$ is 4D corresponding\n",
      "to the four components explained above. $Y \\in \\{0,1\\}$ are the scalar \n",
      "labels of a class. In other words  \n",
      "the species labels are your $Y$ data (say versicolor = 0 and virginica=1), and the four features, petal length\n",
      "and width, sepal length and width, are your $X$ data. \n",
      "\n",
      "The goal is to train a classifier, that will predict an unknown class label $\\hat{y}$ from a new data point $\\hat{x}$. \n",
      "\n",
      "Consider the following model (logistic model) for the probability of a class:\n",
      "\n",
      "$$ Y \\sim \\frac{1}{1+e^{-X^T \\beta}} $$\n",
      "\n",
      "where $\\beta$ is a 4D parameter to learn. \n",
      "\n",
      " \n",
      "1. Choose a prior for $\\beta \\sim N(0, \\sigma^2 I) $ and write down the formula for the normalized posterior $p(\\beta| Y,X)$. Note: You can choose $\\sigma$ as you think fit (we wont be modeling it to a deeper level). \n",
      "2. Implement a MH or slice sampler to sample from this posterior of $\\beta$.   Use the first 30 rows for each species as training data and leave out the last 20 rows for each species as test data (for a total of 60 training and 40 testing). Generate samples of $\\beta$ and plot the sequence of $\\beta$'s  and histograms for each $\\beta$ component. \n",
      "3. Use the $\\beta$ samples to get a prediction, $\\hat{y}$ of the class labels for the test data and compare the predicted labels with the true labels and see how well you did by estimating the average error rate, $E[ | y-\\hat{y} | ]$. \n",
      "\n",
      "HINT:  \n",
      "You *may* need to add an extra constant term to your X vector, i.e. $X=(1, x_1, x_2, x_3, x_4)$\n",
      "in order for this to work properly. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Question 3. Where and which are the stars?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When  celestial point sources (stars)  are observed via an imaging system (telescope) \n",
      "the resulting image is an extended blob that represents the unresolved source. This blob \n",
      "is also known as the point spread function (PSF). The point spread function (PSF) describes \n",
      "the response of an imaging system to a point source. \n",
      "Often the   PSF can be modeled as a Gaussian \n",
      "\n",
      "$$  I(r|\\mu, \\sigma) =  \\frac{A}{ 2\\pi \\sigma^2} e^{-(\\vec{r}-\\vec{\\mu})^2/2\\sigma^2} $$\n",
      "\n",
      " where $\\vec{r}$ is the position on the image,  $\\vec{\\mu}$ \n",
      "the position of the source on the image,  $\\sigma$ the width of the PSF (this should be the same for \n",
      "all sources) and A the  intensity of the source. \n",
      "\n",
      "1. Consider the case of two  stars and use the observation image given in [EMPSF_NB.txt](./files/EMPSF_NB.txt). The file contains  the number of photons observed at each pixel $i,j=32\\times32$.  Use the EM method to estimate the positions of the two stars ($\\mu$),  the width of PSF ($\\sigma$) and their intensity  $A$'s. \n",
      "\n",
      "2. Now consider the case where the sky is not totally dark and therefore there are photons detected at  each pixel that are from the background light. We model the background as a third mixture component, this time with a poisson distribution. Assume that the background is uniform across the image, so that $\\lambda$ is  $1/( 32^2)$. \n",
      "\n",
      "[EMPSF.txt](./files/EMPSF.txt) contains the observations with such background light. Use  the EM method to estimate the positions, width, intensities and background light (intensity per pixel). \n",
      "\n",
      "HINT: the intensities are the mixture probabilities times the total photon count."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}